{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605fd93e",
   "metadata": {},
   "source": [
    "# 문제를 풀기 위한 빌드업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                 'machine-learning-databases'\n",
    "                 '/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "\n",
    "# UCI 머신 러닝 저장소에서 유방암 데이터셋을 다운로드할 수 없을 때\n",
    "# 다음 주석을 해제하고 로컬 경로에서 데이터셋을 적재하세요:\n",
    "\n",
    "# df = pd.read_csv('wdbc.data', header=None)\n",
    "\n",
    "df.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.20,\n",
    "                     stratify=y,\n",
    "                     random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=2),\n",
    "                        LogisticRegression(random_state=1))\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7f4df",
   "metadata": {},
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=pipe_lr, \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                param_name='logisticregression__C', \n",
    "                param_range=param_range,\n",
    "                cv=10)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='blue', marker='o', \n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='green', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244dd3e4",
   "metadata": {},
   "source": [
    "# validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        LogisticRegression(penalty='l2', random_state=1,\n",
    "                                           max_iter=10000))\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=pipe_lr,\n",
    "                               X=X_train,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                               cv=10,\n",
    "                               n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/06_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffd6af",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac3cd3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219841ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import warnings\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8306fc6",
   "metadata": {},
   "source": [
    "## Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d301fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('column_2C_weka.csv')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074b93a",
   "metadata": {},
   "source": [
    "## K-NEAREST NEIGHBORS (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3bf4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "x,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\n",
    "knn.fit(x,y)\n",
    "prediction = knn.predict(x)\n",
    "print('Prediction: {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82993eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "x,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\n",
    "knn.fit(x_train,y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test)) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc87499",
   "metadata": {},
   "source": [
    "## ROC Curve with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7456fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve with logistic regression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# abnormal = 1 and normal = 0\n",
    "data['class_binary'] = [1 if i == 'Abnormal' else 0 for i in data.loc[:,'class']]\n",
    "x,y = data.loc[:,(data.columns != 'class') & (data.columns != 'class_binary')], data.loc[:,'class_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred_prob = logreg.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caca54",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61476d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'n_neighbors': np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=3) # GridSearchCV\n",
    "knn_cv.fit(x,y)# Fit\n",
    "\n",
    "# Print hyperparameter\n",
    "print(\"Tuned hyperparameter k: {}\".format(knn_cv.best_params_)) \n",
    "print(\"Best score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033409aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-3, 3, 7), 'penalty': ['l1', 'l2']}\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3,random_state = 12)\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg,param_grid,cv=3)\n",
    "logreg_cv.fit(x_train,y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned hyperparameters : {}\".format(logreg_cv.best_params_))\n",
    "print(\"Best Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "007c271ed923db35e3d4cb43aeed96ded8f2678f6d053a6862145e221fe6b026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
